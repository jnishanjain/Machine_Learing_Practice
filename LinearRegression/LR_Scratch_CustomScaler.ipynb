{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EDfcSmn4QafJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are creating really high values so we can show case how its harder for Gradient decent to\n",
        "np.random.seed(59)\n",
        "X = np.random.randint(0,1000000,(50000,5))\n",
        "weights = np.array([-69,4,28,67,74])\n",
        "bias = 987\n",
        "y = np.dot(X,weights) + bias\n"
      ],
      "metadata": {
        "id": "SZ7uRU5gFJNU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking our data\n",
        "print(X.shape)\n",
        "print(X[:5,:])\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "BP9KUhI-R-XB",
        "outputId": "b9b8c063-a8e9-4638-a32e-01640bc833b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 5)\n",
            "[[889009 744876 668877 918167 927083]\n",
            " [678095 741173 645177 375168 911199]\n",
            " [865347 119104 760403 535031  66861]\n",
            " [ 33758 415705 696752 787273 229012]\n",
            " [286437 998466 368246 334113 857291]]\n",
            "(50000,)\n",
            "[ 90488757  66807062   2854535 ...  16161166 115690186  83172750]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LineraRegression:\n",
        "  def __init__(self,learning_rate = 0.1,max_iterations=10000):\n",
        "    self.lr = learning_rate\n",
        "    self.max_itr = max_iterations\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "    self.loss_history = []\n",
        "\n",
        "  def fit(self,X,y):\n",
        "    #lets initialize weights first\n",
        "    n_samples , n_features = X.shape\n",
        "    self.weights = np.zeros(n_features)\n",
        "    self.bias = 0\n",
        "    for epoch in range(self.max_itr):\n",
        "      y_pred = self.predict(X)\n",
        "      error = y_pred - y\n",
        "      dw = 2/n_samples * np.dot(X.T,error)\n",
        "      db = 2/n_samples * np.sum(error)\n",
        "      self.weights = self.weights - self.lr*dw\n",
        "      self.bias = self.bias -self.lr*db\n",
        "      loss = np.mean(error**2)\n",
        "      self.loss_history.append(np.mean(error**2))\n",
        "      if epoch % 1000 == 0 :\n",
        "        print(f\"Epoch {epoch} , Loss {loss}\")\n",
        "  def predict(self,X):\n",
        "    return np.dot(X,self.weights) + self.bias\n"
      ],
      "metadata": {
        "id": "8FcTA7YF_j_C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LineraRegression(learning_rate=0.00001)\n",
        "model.fit(X,y)"
      ],
      "metadata": {
        "id": "uFJ0ez5WST7-",
        "outputId": "0ad3cc18-d956-419f-82ff-d804615426ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 , Loss 3986933616990935.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-600002137.py:21: RuntimeWarning: overflow encountered in square\n",
            "  loss = np.mean(error**2)\n",
            "/tmp/ipython-input-600002137.py:22: RuntimeWarning: overflow encountered in square\n",
            "  self.loss_history.append(np.mean(error**2))\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/tmp/ipython-input-600002137.py:19: RuntimeWarning: invalid value encountered in subtract\n",
            "  self.weights = self.weights - self.lr*dw\n",
            "/tmp/ipython-input-600002137.py:20: RuntimeWarning: invalid value encountered in scalar subtract\n",
            "  self.bias = self.bias -self.lr*db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000 , Loss nan\n",
            "Epoch 2000 , Loss nan\n",
            "Epoch 3000 , Loss nan\n",
            "Epoch 4000 , Loss nan\n",
            "Epoch 5000 , Loss nan\n",
            "Epoch 6000 , Loss nan\n",
            "Epoch 7000 , Loss nan\n",
            "Epoch 8000 , Loss nan\n",
            "Epoch 9000 , Loss nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see our data vales are too high, and python throws as overflow error because our values become too large, there is a solution for this which is Scaling, so now we will scale out data using a StandardScaler method."
      ],
      "metadata": {
        "id": "lRqpy4BaTyvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StandardScalar:\n",
        "  def __init__(self,):\n",
        "    pass"
      ],
      "metadata": {
        "id": "F8quEOXQSfSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}